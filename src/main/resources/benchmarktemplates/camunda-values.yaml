# Chart values for the Camunda Platform 8 Helm chart.
# This file deliberately contains only the values that differ from the defaults.
# For changes and documentation, use your favorite diff tool to compare it with:
# https://github.com/camunda/camunda-platform-helm/blob/main/charts/camunda-platform/values.yaml

global:
  elasticsearch:
    enabled: ${elasticSearch.enabled}
  ingress:
    enabled: ${optimize.enabled}
    className: nginx
    host: "falko-benchmark.gke.c8sm.com"
    tls:
      enabled: true
      secretName: "tls-secret"
  identity:
    auth:
      # Disabling the Identity authentication
      # it will fall back to basic-auth: demo/demo as default user
      enabled: ${optimize.enabled}
      publicIssuerUrl: "https://falko-benchmark.gke.c8sm.com/auth/realms/camunda-platform"
      identity:
        recirectUrl: "https://falko-benchmark.gke.c8sm.com/identity"
      operate:
        redirectUrl: "https://falko-benchmark.gke.c8sm.com/operate"
      tasklist:
        redirectUrl: "https://falko-benchmark.gke.c8sm.com/tasklist"
      optimize:
        redirectUrl: "https://falko-benchmark.gke.c8sm.com/optimize"
      connectors:
        redirectUrl: "https://falko-benchmark.gke.c8sm.com/connectors"
      webModeler:
        redirectUrl: "https://falko-benchmark.gke.c8sm.com/modeler"
      console:
        redirectUrl: "https://falko-benchmark.gke.c8sm.com/console"

zeebe:
  # affinity:
  #   podAntiAffinity: null
  nodeSelector:
    cloud.google.com/gke-nodepool: pool-${engine.machineType}
#    alpha.eksctl.io/nodegroup-name: c7g-8xlarge
  resources:
    requests:
      cpu: ${engine.vcpuRequest}
      memory: ${engine.ram}Gi
    limits:
      cpu: null
      memory: ${engine.ram}Gi
  clusterSize: "${engine.clusterSize}"
  partitionCount: "${engine.partitions}"
  replicationFactor: "${engine.replicationFactor}"
  cpuThreadCount: ${engine.cpuThreadPoolSizeNode}
  ioThreadCount: ${engine.ioThreadPoolSizeNode}
  persistenceType: ${engine.diskType}
  pvcSize: ${engine.diskSize}Gi
  pvcStorageClassName: ${engine.fileSystem}
  # initContainers:
  #   - name: init-exporter-job-worker
  #     image: curlimages/curl:latest
  #     command: ["/bin/sh", "-c"]
  #     args: [
  #       "curl -L https://camunda.jfrog.io/artifactory/camunda-bpm-community-extensions/org/camunda/community/extension/zeebe/exporter/jobworker/zeebe-embedded-job-worker/0.0.10/zeebe-embedded-job-worker-0.0.10.jar -o /exporters/zeebe-embedded-job-worker-0.0.10.jar; ls -al /exporters"
  #     ]
  #     securityContext:
  #       runAsUser: 1001
  #       runAsNonRoot: true
  #     volumeMounts:
  #     - name: exporters
  #       mountPath: /exporters/
  # extraVolumes:
  #   - name: exporters-writable
  #     emptyDir: {}
  # extraVolumeMounts:
  #   - name: exporters-writable
  #     mountPath: /usr/local/zeebe/exporters/
  env:
    # - name: ZEEBE_BROKER_EXPORTERS_JOBWORKER_JARPATH
    #   value: exporters/zeebe-embedded-job-worker-0.0.10.jar
    # - name: ZEEBE_BROKER_EXPORTERS_JOBWORKER_CLASSNAME
    #   value: org.camunda.community.extension.zeebe.exporter.jobworker.EmbeddedJobWorker
    # comment out ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH* when disabling Elasticsearch
    #- name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_NUMBEROFSHARDS
    #  value: "${elasticSearch.shardsPerIndex}"
    #- name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_NUMBEROFREPLICAS
    #  value: "1"
    # Export to separate Elasticsearch for Optimize
    #- name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCHOPTIMIZE_CLASSNAME
    #  value: io.camunda.zeebe.exporter.ElasticsearchExporter
    #- name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCHOPTIMIZE_ARGS_URL
    #  value: http://optimize-elasticsearch:9200
    #- name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCHOPTIMIZE_ARGS_INDEX_NUMBEROFSHARDS
    #  value: "3"
    #- name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCHOPTIMIZE_ARGS_INDEX_NUMBEROFREPLICAS
    #  value: "1"
    - name: ZEEBE_BROKER_CLUSTER_RAFT_FLUSH_DELAYTIME
      value: "${engine.raftFlushDelay}"
    - name: ZEEBE_BROKER_EXECUTION_METRICS_EXPORTER_ENABLED
      value: "true"
    - name: ZEEBE_BROKER_EXECUTIONMETRICSEXPORTERENABLED
      value: "true"
    - name: ZEEBE_BROKER_EXPERIMENTAL_FEATURES_ENABLEACTORMETRICS
      value: "true"
    - name: ZEEBE_BROKER_DATA_LOGSEGMENTSIZE
      value: "${engine.logSegmentSize}MB"
    - name: ZEEBE_BROKER_EXPERIMENTAL_RAFT_PREALLOCATESEGMENTFILES
      value: "${engine.preAllocateSegmentFiles}"
    - name: ZEEBE_BROKER_EXPERIMENTAL_DISABLEEXPLICITRAFTFLUSH
      value: "${engine.disableExplicitRaftFlush}"
    - name: ZEEBE_BROKER_BACKPRESSURE_ENABLED
      value: "${engine.backpressure}"
    - name: ZEEBE_BROKER_BACKPRESSURE_USEWINDOWED
      value: "${engine.bpUseWindowed}"
    - name: ZEEBE_BROKER_BACKPRESSURE_ALGORITHM
      value: "${engine.backPressureAlgorithm}"
    - name: ZEEBE_BROKER_BACKPRESSURE_FIXED_LIMIT
      value: "${engine.initialLimit}"
    - name: ZEEBE_BROKER_BACKPRESSURE_VEGAS_INITIALLIMIT
      value: "${engine.initialLimit}"
    - name: ZEEBE_BROKER_BACKPRESSURE_VEGAS_ALPHA
      value: "${engine.vegasAlpha}"
    - name: ZEEBE_BROKER_BACKPRESSURE_VEGAS_BETA
      value: "${engine.vegasBeta}"
    - name: ZEEBE_BROKER_BACKPRESSURE_GRADIENT_MINLIMIT
      value: "${engine.minLimit}"
    - name: ZEEBE_BROKER_BACKPRESSURE_GRADIENT_INITIALLIMIT
      value: "${engine.initialLimit}"
    - name: ZEEBE_BROKER_BACKPRESSURE_GRADIENT_RTTTOLERANCE
      value: "${engine.rttTolerance}"
    - name: "ZEEBE_BROKER_CLUSTER_MESSAGECOMPRESSION"
      value: "${engine.networkCompression}"
    - name: ZEEBE_BROKER_EXPERIMENTAL_MAXAPPENDSPERFOLLOWER
      value: "${engine.maxAppendsPerFollower}"
    - name: ZEEBE_BROKER_EXPERIMENTAL_MAXAPPENDBATCHSIZE
      value: "${engine.maxAppendBatchSize}KB"
    - name: ZEEBE_BROKER_EXPERIMENTAL_ROCKSDB_DISABLEWAL
      value: "${rocksdb.disableWal}"
    - name: ZEEBE_BROKER_EXPERIMENTAL_ROCKSDB_ENABLESSTPARTITIONING
      value: "${rocksdb.enableSstPartitioning}"
    - name: ZEEBE_BROKER_EXPERIMENTAL_ROCKSDB_MEMORYLIMIT
      value: "${rocksdb.memoryLimit}"
    # Enable JSON logging for Google Cloud Stackdriver
    - name: ZEEBE_LOG_APPENDER
      value: Stackdriver
    - name: ZEEBE_LOG_STACKDRIVER_SERVICENAME
      value: zeebe
    - name: ZEEBE_LOG_STACKDRIVER_SERVICEVERSION
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace

zeebeGateway:
  # affinity:
  #   podAntiAffinity: null
  contextPath: "/rest"
#  podAnnotations:
#    linkerd.io/inject: enabled
#    config.linkerd.io/opaque-ports: "26500"
  ingress:
    grpc:
      enabled: true
      host: "falko-benchmark.gke.c8sm.com"
      tls:
        enabled: true
        secretName: "tls-secret"
    rest:
      enabled: true
      host: "falko-benchmark.gke.c8sm.com"
      path: "/rest"
      tls:
        enabled: true
        secretName: "tls-secret"
  replicas: ${gateway.replicas}
  nodeSelector:
    cloud.google.com/gke-nodepool: pool-${engine.machineType}
#    alpha.eksctl.io/nodegroup-name: c7g-8xlarge
  resources:
    requests:
      cpu: ${gateway.vcpus}
      memory: ${gateway.ram}Gi
    limits:
      cpu: null
      memory: ${gateway.ram}Gi
  env:
    - name: ZEEBE_GATEWAY_MONITORING_ENABLED
      value: "true"
    - name: ZEEBE_GATEWAY_THREADS_MANAGEMENTTHREADS
      value: "${gateway.numberOfThreads}"
    - name: ZEEBE_GATEWAY_CLUSTER_MESSAGECOMPRESSION
      value: "${engine.networkCompression}"
    # Enable JSON logging for Google Cloud Stackdriver
    - name: ZEEBE_LOG_APPENDER
      value: Stackdriver
    - name: ZEEBE_LOG_STACKDRIVER_SERVICENAME
      value: zeebe
    - name: ZEEBE_LOG_STACKDRIVER_SERVICEVERSION
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: ZEEBE_GATEWAY_SECURITY_AUTHENTICATION_MODE
      value: "none"

operate:
  enabled: ${operate.enabled}
  contextPath: "/operate"
  nodeSelector:
    cloud.google.com/gke-nodepool: pool-${engine.machineType}
  resources:
    requests:
      cpu: ${operate.vcpus}
      memory: ${operate.ram}Gi
    limits:
      cpu: ${operate.vcpus}
      memory: ${operate.ram}Gi
  env:
    - name: JAVA_OPTS
      value: -XX:MaxRAMPercentage=50.0 -XX:InitialRAMPercentage=25.0
    - name: CAMUNDA_OPERATE_ARCHIVER_ROLLOVERBATCHSIZE
      value: "${operate.archRolloverBatchSize}"
    - name: CAMUNDA_OPERATE_ARCHIVER_THREADSCOUNT
      value: "${operate.archThreads}"
    - name: CAMUNDA_OPERATE_IMPORTER_QUEUESIZE
      value: "${operate.importerQueueSize}"
    - name: CAMUNDA_OPERATE_IMPORTER_READERTHREADSCOUNT
      value: "${operate.importerReaderThreads}"
    - name: CAMUNDA_OPERATE_IMPORTER_THREADSCOUNT
      value: "${operate.importerThreads}"
    - name: CAMUNDA_OPERATE_ELASTICSEARCH_NUMBEROFSHARDS
      value: "${elasticSearch.shardsPerIndex}"
    - name: CAMUNDA_OPERATE_ELASTICSEARCH_NUMBEROFREPLICAS
      value: "1"
    - name: CAMUNDA_OPERATE_ZEEBEELASTICSEARCH_BATCHSIZE
      value: "${operate.importPageSize}"
  configuration: |
    server:
      servlet:
        context-path: "/operate"
    management:
      server:
        base-path: "/operate"

    spring:
      servlet:
        multipart:
          max-file-size: "10MB"
          max-request-size: "10MB"
      profiles:
        active: "identity-auth"
      security:
        oauth2:
          resourceserver:
            jwt:
              issuer-uri: "http://camunda-keycloak:80/auth/realms/camunda-platform"
              jwk-set-uri: "http://camunda-keycloak:80/auth/realms/camunda-platform/protocol/openid-connect/certs"
    camunda:
      identity:
        clientId: "operate"
        audience: "operate-api"

    # Camunda Database configuration
    camunda.database:
      type: elasticsearch
      # Cluster name
      clusterName: elasticsearch
      # Elasticsearch full url
      url: "http://camunda-elasticsearch:9200"

    # Operate configuration file
    camunda.operate:
      identity:
        redirectRootUrl: "https://falko-benchmark.gke.c8sm.com"

      # ELS instance to store Operate data
      elasticsearch:
        # Cluster name
        clusterName: elasticsearch
        # Host
        host: camunda-elasticsearch
        # Transport port
        port: 9200
        # Elasticsearch full url
        url: "http://camunda-elasticsearch:9200"
        numberOfShards: ${elasticSearch.shardsPerIndex}
        numberOfReplicas: 1
      # ELS instance to export Zeebe data to
      zeebeElasticsearch:
        # Cluster name
        clusterName: elasticsearch
        # Host
        host: camunda-elasticsearch
        # Transport port
        port: 9200
        # Index prefix, configured in Zeebe Elasticsearch exporter
        prefix: zeebe-record
        # Elasticsearch full url
        url: "http://camunda-elasticsearch:9200"
      # Zeebe instance
      zeebe:
        # Gateway address
        gatewayAddress: "camunda-zeebe-gateway:26500"
    logging:
      level:
        ROOT: INFO
        io.camunda.operate: INFO
    #Spring Boot Actuator endpoints to be exposed
    management.endpoints.web.exposure.include: health,info,conditions,configprops,prometheus,loggers,usage-metrics,backups


tasklist:
  enabled: ${operate.enabled}
  contextPath: "/tasklist"
  nodeSelector:
    cloud.google.com/gke-nodepool: pool-${engine.machineType}
  resources:
    requests:
      cpu: ${operate.vcpus}
      memory: ${operate.ram}Gi
    limits:
      cpu: ${operate.vcpus}
      memory: ${operate.ram}Gi
  env:
    - name: JAVA_OPTS
      value: -XX:MaxRAMPercentage=50.0 -XX:InitialRAMPercentage=25.0
    - name: CAMUNDA_TASKLIST_ARCHIVER_ROLLOVERBATCHSIZE
      value: "${operate.archRolloverBatchSize}"
    - name: CAMUNDA_TASKLIST_ARCHIVER_THREADSCOUNT
      value: "${operate.archThreads}"
    - name: CAMUNDA_TASKLIST_IMPORTER_QUEUESIZE
      value: "${operate.importerQueueSize}"
    - name: CAMUNDA_TASKLIST_IMPORTER_READERTHREADSCOUNT
      value: "${operate.importerReaderThreads}"
    - name: CAMUNDA_TASKLIST_IMPORTER_THREADSCOUNT
      value: "${operate.importerThreads}"
    - name: CAMUNDA_TASKLIST_ELASTICSEARCH_NUMBEROFSHARDS
      value: "${elasticSearch.shardsPerIndex}"
    - name: CAMUNDA_TASKLIST_ELASTICSEARCH_NUMBEROFREPLICAS
      value: "1"
    - name: CAMUNDA_TASKLIST_ZEEBEELASTICSEARCH_BATCHSIZE
      value: "${operate.importPageSize}"

optimize:
  enabled: ${optimize.enabled}
  contextPath: "/optimize"
  partitionCount: "${engine.partitions}"
  nodeSelector:
    cloud.google.com/gke-nodepool: pool-${engine.machineType}
  resources:
    requests:
      cpu: "${optimize.vcpus}"
      memory: ${optimize.ram}Gi
    limits:
      cpu: "${optimize.vcpus}"
      memory: ${optimize.ram}Gi
  env:
    - name: JAVA_OPTS
      value: -XX:MaxRAMPercentage=50.0 -XX:InitialRAMPercentage=25.0
    # Second Elasticsearch for Optimize
    #- name: OPTIMIZE_ELASTICSEARCH_HOST
    #  value: optimize-elasticsearch
    - name: CAMUNDA_OPTIMIZE_ZEEBE_MAX_IMPORT_PAGE_SIZE
      value: "${optimize.importPageSize}"
    - name: CAMUNDA_OPTIMIZE_JOB_EXECUTOR_QUEUE_SIZE
      value: "${optimize.importerQueueSize}"
    - name: CAMUNDA_OPTIMIZE_JOB_EXECUTOR_THREAD_COUNT
      value: "${optimize.importerThreads}"
    - name: CAMUNDA_OPTIMIZE_ELASTICSEARCH_SETTINGS_INDEX_NUMBER_OF_SHARDS
      value: "${optimize.shardsPerIndex}"
    - name: CAMUNDA_OPTIMIZE_ELASTICSEARCH_SETTINGS_INDEX_NUMBER_OF_REPLICAS
      value: "1"
    - name: CAMUNDA_OPTIMIZE_HISTORYCLEANUP_CRONTRIGGER
      value: "0 18 * * *"
    - name: CAMUNDA_OPTIMIZE_HISTORYCLEANUP_TTL
      value: "P5D"
    - name: CAMUNDA_OPTIMIZE_HISTORYCLEANUP_PROCESSDATACLEANUP_ENABLED
      value: "true"
    - name: CAMUNDA_OPTIMIZE_HISTORYCLEANUP_PROCESSDATACLEANUP_CLEANUPMODE
      value: "all"
    - name: CAMUNDA_OPTIMIZE_HISTORYCLEANUP_PROCESSDATACLEANUP_BATCHSIZE
      value: "10000"

connectors:
  enabled: false
  inbound:
    mode: oauth
  contextPath: "/connectors"

webModeler:
  enabled: false
  contextPath: "/modeler"
  image:
    pullSecrets:
      - name: camunda-docker-registry
  restapi:
    mail:
      fromAddress: YOUR_EE_EMAIL
  env:
    - name: PLAY_ENABLED
      value: true

console:
  enabled: ${optimize.enabled}
  contextPath: "/console"

identity:
  enabled: ${optimize.enabled}
  contextPath: "/identity"
  fullURL: "https://falko-benchmark.gke.c8sm.com/identity"

identityKeycloak:
  enabled: ${optimize.enabled}
  extraEnvVars:
    - name: KEYCLOAK_PROXY_ADDRESS_FORWARDING
      value: "true"
    - name: KEYCLOAK_FRONTEND_URL
      value: "https://falko-benchmark.gke.c8sm.com/auth"
  postgresql:
    primary:
      resourcesPreset: micro

postgresql:
  enabled: false

prometheusServiceMonitor:
  enabled: true

elasticsearch:
  enabled: ${elasticSearch.enabled}
  image:
    tag: ${elasticSearch.version}
  master:
    masterOnly: ${elasticSearch.masterOnly}
    replicaCount: ${elasticSearch.clusterSizeMaster}
    nodeSelector:
      cloud.google.com/gke-nodepool: pool-${engine.machineType}
    resources:
      requests:
        cpu: ${elasticSearch.vcpusMasterRequests}
        memory: ${elasticSearch.ramMaster}Gi
      limits:
        cpu: ${elasticSearch.vcpusMaster}
        memory: ${elasticSearch.ramMaster}Gi
    heapSize: ${elasticSearch.heapSizeMaster}m
    persistence:
      size: ${elasticSearch.storageCapacity}Gi
      storageClass: ${elasticSearch.fileSystem}
  data:
    replicaCount: ${elasticSearch.clusterSizeData}
    nodeSelector:
      cloud.google.com/gke-nodepool: pool-${engine.machineType}
    resources:
      requests:
        cpu: ${elasticSearch.vcpusDataRequests}
        memory: ${elasticSearch.ramData}Gi
      limits:
        cpu: ${elasticSearch.vcpusData}
        memory: ${elasticSearch.ramData}Gi
    heapSize: ${elasticSearch.heapSizeData}m
    persistence:
      size: ${elasticSearch.storageCapacity}Gi
      storageClass: ${elasticSearch.fileSystem}
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      honorLabels: true
      namespace: default
      labels:
        release: metrics
    resourcesPreset: small
